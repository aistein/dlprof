{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of Work So Far"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) \"Joint Deep Modelling ... Recommendation Engine\"\n",
    "* Creation completed\n",
    "    - Feed Dict vs. TF Records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Testing of NVVP, NVPROF, TFTRACE in progress\n",
    "* NVVP/NVPROF\n",
    "    - have installed software to allow remote GUI desktop access to use this software\n",
    "    - the problem is that the nvidia profiles are far too granular to understand from a high level perspective\n",
    "* TFTRACE\n",
    "    - the native tensorflow chrome-traces are the best option available\n",
    "    - the currently working on one profiling comparsions\n",
    "        * the comparison of the \"joint deep modeling\" project TF implementation vs. keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) TF Recommended Optimizations Exploration\n",
    "* Applying tensorflow best practices for optimization (cpu, gpu, general) to two projects\n",
    "    - MIT Deep Learning Labs music generation (runs on docker)\n",
    "    - Spectral Representation of CNN's - tensorflow optimizations\n",
    "    - Basic \"Accelerated Linear Algebra\" XLA JIT Compiler\n",
    "        * so far, have not been able to get this feature working"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Undocumented or Poorly Documented Tensorflow Features\n",
    "* Tensorflow visual debugger\n",
    "    - Setting up the visual debugger and stepping through graph execution\n",
    "* Tensorflow Data Input\n",
    "    - Creating tfrecords\n",
    "    - Reading tfrecords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XLA Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/tensorflow/mnist/input_data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data/t10k-labels-idx1-ubyte.gz\n",
      "0.9186\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ecbm6040-as5281/miniconda3/envs/e6040-pil/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2918: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Simple MNIST classifier example with JIT XLA and timelines.\n",
    "\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from tensorflow.python.client import timeline\n",
    "\n",
    "FLAGS = None\n",
    "\n",
    "\n",
    "def main(_):\n",
    "  # Import data\n",
    "  mnist = input_data.read_data_sets(FLAGS.data_dir)\n",
    "\n",
    "  # Create the model\n",
    "  x = tf.placeholder(tf.float32, [None, 784])\n",
    "  w = tf.Variable(tf.zeros([784, 10]))\n",
    "  b = tf.Variable(tf.zeros([10]))\n",
    "  y = tf.matmul(x, w) + b\n",
    "\n",
    "  # Define loss and optimizer\n",
    "  y_ = tf.placeholder(tf.int64, [None])\n",
    "\n",
    "  # The raw formulation of cross-entropy,\n",
    "  #\n",
    "  #   tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(tf.nn.softmax(y)),\n",
    "  #                                 reduction_indices=[1]))\n",
    "  #\n",
    "  # can be numerically unstable.\n",
    "  #\n",
    "  # So here we use tf.losses.sparse_softmax_cross_entropy on the raw\n",
    "  # logit outputs of 'y', and then average across the batch.\n",
    "  cross_entropy = tf.losses.sparse_softmax_cross_entropy(labels=y_, logits=y)\n",
    "  train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "\n",
    "  config = tf.ConfigProto()\n",
    "  jit_level = 0\n",
    "  if FLAGS.xla:\n",
    "    # Turns on XLA JIT compilation.\n",
    "    jit_level = tf.OptimizerOptions.ON_1\n",
    "\n",
    "  config.graph_options.optimizer_options.global_jit_level = jit_level\n",
    "  run_metadata = tf.RunMetadata()\n",
    "  sess = tf.Session(config=config)\n",
    "  tf.global_variables_initializer().run(session=sess)\n",
    "  # Train\n",
    "  train_loops = 1000\n",
    "  for i in range(train_loops):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "\n",
    "    # Create a timeline for the last loop and export to json to view with\n",
    "    # chrome://tracing/.\n",
    "    if i == train_loops - 1:\n",
    "      sess.run(train_step,\n",
    "               feed_dict={x: batch_xs,\n",
    "                          y_: batch_ys},\n",
    "               options=tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE),\n",
    "               run_metadata=run_metadata)\n",
    "      trace = timeline.Timeline(step_stats=run_metadata.step_stats)\n",
    "      with open('timeline.ctf.json', 'w') as trace_file:\n",
    "        trace_file.write(trace.generate_chrome_trace_format())\n",
    "    else:\n",
    "      sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "\n",
    "  # Test trained model\n",
    "  correct_prediction = tf.equal(tf.argmax(y, 1), y_)\n",
    "  accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "  print(sess.run(accuracy,\n",
    "                 feed_dict={x: mnist.test.images,\n",
    "                            y_: mnist.test.labels}))\n",
    "  sess.close()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  parser = argparse.ArgumentParser()\n",
    "  parser.add_argument(\n",
    "      '--data_dir',\n",
    "      type=str,\n",
    "      default='/tmp/tensorflow/mnist/input_data',\n",
    "      help='Directory for storing input data')\n",
    "  parser.add_argument(\n",
    "      '--xla', type=bool, default=True, help='Turn xla via JIT on')\n",
    "  FLAGS, unparsed = parser.parse_known_args()\n",
    "  tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chrome trace generated with the above code is shown below.  Note that XLA is not working!  If it were working, the GPU operations would be 1 or two \"fused\" XLA operations, not the 100's of individual math ops we see here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"mnist_xla/xla_trace_broken.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
