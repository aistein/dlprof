{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/venv/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import tensorflow as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode):\n",
    "    emb_size = 50\n",
    "    batch_size=2\n",
    "    review_trunc_len=2\n",
    "    filters=10\n",
    "    kernel_size=3\n",
    "    \n",
    "    with open(\"data/dictionary.pkl\", \"rb\") as f:\n",
    "        dictionary = pkl.load(f)\n",
    "    \n",
    "    values = list(range(len(dictionary)))\n",
    "    keys = list(dictionary)\n",
    "    \n",
    "    table = tf.contrib.lookup.HashTable(\n",
    "      tf.contrib.lookup.KeyValueTensorInitializer(keys, values), -1\n",
    "    )\n",
    "    \n",
    "    word_embeddings = tf.get_variable(\n",
    "        \"word_embeddings\",\n",
    "        shape=[len(dictionary), emb_size]\n",
    "    )\n",
    "    \n",
    "    u_inputs = features[0]\n",
    "    i_inputs = features[1]\n",
    "    \n",
    "    u_inputs = table.lookup(u_inputs)\n",
    "    i_inputs = table.lookup(i_inputs)\n",
    "\n",
    "    u_inputs = tf.nn.embedding_lookup(word_embeddings, u_inputs)\n",
    "    i_inputs = tf.nn.embedding_lookup(word_embeddings, i_inputs)\n",
    "    \n",
    "    user_conv1 = tf.layers.conv1d(\n",
    "        u_inputs,\n",
    "        filters,\n",
    "        kernel_size,\n",
    "        use_bias=True,\n",
    "        activation=tf.nn.relu,\n",
    "        name=\"user_conv\")\n",
    "\n",
    "    item_conv1 = tf.layers.conv1d(\n",
    "        i_inputs,\n",
    "        filters,\n",
    "        kernel_size,\n",
    "        use_bias=True,\n",
    "        activation=tf.nn.relu,\n",
    "        name=\"item_conv\")\n",
    "\n",
    "    user_max_pool1 = tf.layers.max_pooling1d(user_conv1, 2, 1)\n",
    "    item_max_pool1 = tf.layers.max_pooling1d(item_conv1, 2, 1)\n",
    "\n",
    "    user_flat = tf.layers.flatten(user_max_pool1)\n",
    "    item_flat = tf.layers.flatten(item_max_pool1)\n",
    "\n",
    "    dense = tf.layers.dense(tf.concat([user_flat, item_flat], 1), 32, activation=tf.nn.relu)\n",
    "    \n",
    "    predictions = tf.layers.dense(dense, 1)\n",
    "    \n",
    "    output = {\n",
    "        \"rating\": predictions,\n",
    "        \"user_review_embedding\": user_flat,\n",
    "        \"item_review_embedding\": item_flat\n",
    "    }\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "\n",
    "    # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "    loss = tf.losses.mean_squared_error(labels, predictions)\n",
    "\n",
    "    # Configure the Training Op (for TRAIN mode)\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=0.0001)\n",
    "        train_op = optimizer.minimize(\n",
    "            loss=loss,\n",
    "            global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "    # Add evaluation metrics (for EVAL mode)\n",
    "    eval_metric_ops = {\n",
    "        \"mean square error\": tf.metrics.mean_squared_error(\n",
    "            labels=labels, predictions=predictions)\n",
    "    }\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "truncate_len = 800\n",
    "batch_size=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_truncate_fn(trunc_len):\n",
    "    def truncate_fn(user, item, rating):\n",
    "        return user[:trunc_len], item[:trunc_len], rating\n",
    "    return truncate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_fn(user, item, rating):\n",
    "    user = tf.string_split(user)\n",
    "    item = tf.string_split(item)\n",
    "    return user.values, item.values, rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_fn(record):\n",
    "    features = {\n",
    "            \"user_review\": tf.FixedLenSequenceFeature([], tf.string, allow_missing=True),\n",
    "            \"item_review\": tf.FixedLenSequenceFeature([], tf.string, allow_missing=True),\n",
    "            \"rating\": tf.FixedLenFeature([1], tf.float32)\n",
    "        }\n",
    "    parsed_features = tf.parse_single_example(record, features)\n",
    "    return parsed_features[\"user_review\"], parsed_features[\"item_review\"], parsed_features[\"rating\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_iterator(loc, batch_size, max_len, pad_value):\n",
    "    dataset = tf.data.TFRecordDataset(loc)\n",
    "    dataset = dataset.map(parse_fn)\n",
    "    dataset = dataset.map(split_fn)\n",
    "    dataset = dataset.map(get_truncate_fn(max_len))\n",
    "    dataset = dataset.padded_batch(batch_size, padded_shapes=([max_len], [max_len], [None]), padding_values=(pad_value, pad_value, 0.0))\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    return iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_input_fn():\n",
    "    train_dataset = get_dataset_iterator(\n",
    "        loc=\"data/train.tfrecords\",\n",
    "        batch_size=batch_size,\n",
    "        max_len=truncate_len,\n",
    "        pad_value=\"unk\")\n",
    "    nex = train_dataset.get_next()\n",
    "    return (nex[0], nex[1]), tf.cast(nex[2], tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_input_fn():\n",
    "    test_dataset = get_dataset_iterator(\n",
    "        loc=\"data/test.tfrecords\",\n",
    "        batch_size=batch_size,\n",
    "        max_len=truncate_len,\n",
    "        pad_value=\"unk\"\n",
    "    )\n",
    "    nex = test_dataset.get_next()\n",
    "    return (nex[0], nex[1]), nex[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'output/model_1523736874', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f1fe6f15128>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "scoring_function = tf.estimator.Estimator(\n",
    "    model_fn=model_fn,\n",
    "    model_dir=\"output/model_\" + str(int(time.time())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /home/ubuntu/miniconda3/envs/venv/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into output/model_1523736874/model.ckpt.\n",
      "INFO:tensorflow:loss = 14.310362, step = 1\n",
      "INFO:tensorflow:global_step/sec: 77.0828\n",
      "INFO:tensorflow:loss = 3.7895236, step = 101 (1.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 73.1551\n",
      "INFO:tensorflow:loss = 0.83002985, step = 201 (1.366 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.4544\n",
      "INFO:tensorflow:loss = 0.44568384, step = 301 (1.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 73.0212\n",
      "INFO:tensorflow:loss = 0.5134324, step = 401 (1.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 71.6201\n",
      "INFO:tensorflow:loss = 0.24153633, step = 501 (1.398 sec)\n",
      "INFO:tensorflow:global_step/sec: 89.3469\n",
      "INFO:tensorflow:loss = 0.1782318, step = 601 (1.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.1351\n",
      "INFO:tensorflow:loss = 1.8608181, step = 701 (1.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.6713\n",
      "INFO:tensorflow:loss = 1.9467124, step = 801 (1.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.8852\n",
      "INFO:tensorflow:loss = 2.9040625, step = 901 (1.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 69.1091\n",
      "INFO:tensorflow:loss = 0.31328487, step = 1001 (1.447 sec)\n",
      "INFO:tensorflow:global_step/sec: 73.5382\n",
      "INFO:tensorflow:loss = 0.14599693, step = 1101 (1.358 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.9497\n",
      "INFO:tensorflow:loss = 0.4060438, step = 1201 (1.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 71.4972\n",
      "INFO:tensorflow:loss = 0.28090137, step = 1301 (1.400 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.2206\n",
      "INFO:tensorflow:loss = 0.53813684, step = 1401 (1.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.4967\n",
      "INFO:tensorflow:loss = 1.071348, step = 1501 (1.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.8235\n",
      "INFO:tensorflow:loss = 0.46652335, step = 1601 (1.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.1593\n",
      "INFO:tensorflow:loss = 2.7272491, step = 1701 (1.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 75.156\n",
      "INFO:tensorflow:loss = 0.6768042, step = 1801 (1.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.7783\n",
      "INFO:tensorflow:loss = 2.2119021, step = 1901 (1.056 sec)\n",
      "INFO:tensorflow:global_step/sec: 89.5211\n",
      "INFO:tensorflow:loss = 0.8841516, step = 2001 (1.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.2173\n",
      "INFO:tensorflow:loss = 2.6076436, step = 2101 (1.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.6501\n",
      "INFO:tensorflow:loss = 1.0849956, step = 2201 (1.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 75.8182\n",
      "INFO:tensorflow:loss = 1.6808201, step = 2301 (1.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 87.4547\n",
      "INFO:tensorflow:loss = 2.4574678, step = 2401 (1.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.3485\n",
      "INFO:tensorflow:loss = 0.8545503, step = 2501 (1.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.9537\n",
      "INFO:tensorflow:loss = 1.527627, step = 2601 (1.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.2968\n",
      "INFO:tensorflow:loss = 0.8885676, step = 2701 (1.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 97.3733\n",
      "INFO:tensorflow:loss = 0.7821057, step = 2801 (1.028 sec)\n",
      "INFO:tensorflow:global_step/sec: 90.52\n",
      "INFO:tensorflow:loss = 0.3484509, step = 2901 (1.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 75.6853\n",
      "INFO:tensorflow:loss = 0.94331837, step = 3001 (1.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.5198\n",
      "INFO:tensorflow:loss = 1.8247855, step = 3101 (1.183 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.9596\n",
      "INFO:tensorflow:loss = 3.0090876, step = 3201 (1.450 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3294 into output/model_1523736874/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.64161193.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x7f1fe6f152b0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from tensorflow.python import debug as tf_debug\n",
    "# hook = tf_debug.TensorBoardDebugHook(\"localhost:6060\")\n",
    "scoring_function.train(input_fn=train_input_fn) #, hooks=[hook])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-04-14-20:15:20\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from output/model_1523736874/model.ckpt-3294\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-04-14-20:15:49\n",
      "INFO:tensorflow:Saving dict for global step 3294: global_step = 3294, loss = 1.1051353, mean square error = 1.1051353\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'global_step': 3294, 'loss': 1.1051353, 'mean square error': 1.1051353}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoring_function.evaluate(input_fn=test_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_movie_lover = \"\"\"i really love action movies they are my favorite kind of movie because i love to watch the good guys\n",
    "win. some of my favorite actors are jet li and jackie chan because they were the last great actors who\n",
    "actually knew how to fight. modern action movie actors are just pretty faces and the editors swap camera\n",
    "angles when supposed hits make contact\"\"\"\n",
    "action_movie_hater = \"\"\"I really hate action movies. jackie chan and jet li are the worst. their old fashioned\n",
    "special effects, if you can even call them that, are out dated and boring. why are people even still paying\n",
    "for them to make movies\"\"\"\n",
    "item = \"\"\"this movie is great because of the way the strong, clever, hero saves the day at the end. as always\n",
    "jackie chans action directing and stunts are amazing, i'm so glad he doesn't use a stunt double liek\n",
    "some other actors that don't need to be mentioned\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predict_input_fn(user, item, trun_len):\n",
    "    def predict_input_fn():\n",
    "        original_user_review = [bytes(v, \"utf8\") for v in user.split()]\n",
    "        original_item_review = [bytes(v, \"utf8\") for v in item.split()]\n",
    "        r_user = tf.constant([original_user_review + [b\"unk\"] * (trun_len - len(original_user_review))])\n",
    "        r_item = tf.constant([original_item_review + [b\"unk\"] * (trun_len - len(original_item_review))])\n",
    "        return (r_user, r_item), None\n",
    "    return predict_input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Input graph does not use tf.data.Dataset or contain a QueueRunner. That means predict yields forever. This is probably a mistake.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from output/model_1523736874/model.ckpt-3294\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "[3.9502964]\n"
     ]
    }
   ],
   "source": [
    "prediction = scoring_function.predict(input_fn=get_predict_input_fn(action_movie_lover, item, truncate_len))\n",
    "print(next(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Input graph does not use tf.data.Dataset or contain a QueueRunner. That means predict yields forever. This is probably a mistake.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from output/model_1523736874/model.ckpt-3294\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "[3.8691864]\n"
     ]
    }
   ],
   "source": [
    "prediction = scoring_function.predict(input_fn=get_predict_input_fn(action_movie_hater, item, truncate_len))\n",
    "print(next(prediction))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
