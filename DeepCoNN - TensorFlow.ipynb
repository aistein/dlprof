{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/venv/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import tensorflow as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode):\n",
    "    emb_size = 50\n",
    "    batch_size=2\n",
    "    review_trunc_len=2\n",
    "    filters=2\n",
    "    kernel_size=10\n",
    "        \n",
    "    word_embeddings = tf.get_variable(\n",
    "        \"word_embeddings\",\n",
    "        shape=[len(dictionary) + 1, emb_size]\n",
    "    )\n",
    "\n",
    "    u_inputs = tf.nn.embedding_lookup(word_embeddings, features[0])\n",
    "    i_inputs = tf.nn.embedding_lookup(word_embeddings, features[1])\n",
    "    \n",
    "    user_conv1 = tf.layers.conv1d(\n",
    "        u_inputs,\n",
    "        filters,\n",
    "        kernel_size,\n",
    "        use_bias=True,\n",
    "        activation=tf.nn.relu,\n",
    "        name=\"user_conv\")\n",
    "\n",
    "    item_conv1 = tf.layers.conv1d(\n",
    "        i_inputs,\n",
    "        filters,\n",
    "        kernel_size,\n",
    "        use_bias=True,\n",
    "        activation=tf.nn.relu,\n",
    "        name=\"item_conv\")\n",
    "\n",
    "    user_max_pool1 = tf.layers.max_pooling1d(user_conv1, 3, 1)\n",
    "    item_max_pool1 = tf.layers.max_pooling1d(item_conv1, 3, 1)\n",
    "\n",
    "    user_flat = tf.layers.flatten(user_max_pool1)\n",
    "    item_flat = tf.layers.flatten(item_max_pool1)\n",
    "\n",
    "    dense = tf.layers.dense(tf.concat([user_flat, item_flat], 1), 16, activation=tf.nn.relu)\n",
    "\n",
    "    logits = tf.layers.dense(dense, 1)\n",
    "    \n",
    "    predictions = {\n",
    "        \"rating\": logits\n",
    "    }\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "\n",
    "    # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "    loss = tf.losses.mean_squared_error(labels, logits)\n",
    "\n",
    "    # Configure the Training Op (for TRAIN mode)\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.0001)\n",
    "        train_op = optimizer.minimize(\n",
    "            loss=loss,\n",
    "            global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "    # Add evaluation metrics (for EVAL mode)\n",
    "    eval_metric_ops = {\n",
    "        \"accuracy\": tf.metrics.accuracy(\n",
    "            labels=labels, predictions=predictions[\"classes\"])}\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "truncate_len = 400\n",
    "batch_size=16\n",
    "def get_pad_fn(max_len, pad_value):\n",
    "    def pad_and_slice(tensor):\n",
    "        padded_vec = tf.pad(tensor, [[0, max_len]], constant_values=tf.constant(pad_value, tf.int64))\n",
    "        return tf.slice(padded_vec, [0], [max_len])\n",
    "    return pad_and_slice\n",
    "\n",
    "def get_parse_fn(pad_fn):\n",
    "    def parse_fn(record):\n",
    "        features = {\n",
    "                \"user_review\": tf.FixedLenSequenceFeature([], tf.int64, allow_missing=True),\n",
    "                \"item_review\": tf.FixedLenSequenceFeature([], tf.int64, allow_missing=True),\n",
    "                \"rating\": tf.FixedLenFeature([1], tf.float32)\n",
    "            }\n",
    "        parsed_features = tf.parse_single_example(record, features)\n",
    "        return pad_fn(parsed_features[\"user_review\"]), pad_fn(parsed_features[\"item_review\"]), parsed_features[\"rating\"]\n",
    "    return parse_fn\n",
    "def get_dataset_iterator(loc, batch_size, max_len, pad_value):\n",
    "    dataset = tf.data.TFRecordDataset(loc)\n",
    "    dataset = dataset.map(get_parse_fn(get_pad_fn(max_len, pad_value)))\n",
    "    dataset = dataset.shuffle(1000)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    return iterator\n",
    "def train_input_fn():\n",
    "    train_dataset = get_dataset_iterator(\n",
    "        loc=\"data/train.tfrecords\",\n",
    "        batch_size=batch_size,\n",
    "        max_len=truncate_len,\n",
    "        pad_value=len(dictionary))\n",
    "    nex = train_dataset.get_next()\n",
    "    return (nex[0], nex[1]), tf.cast(nex[2], tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'output/model_1523499889', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fee63415ef0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "classifier = tf.estimator.Estimator(\n",
    "    model_fn=model_fn,\n",
    "    model_dir=\"output/model_\" + str(int(time.time())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /home/ubuntu/miniconda3/envs/venv/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "47 ops no flops stats due to incomplete shapes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 1 into output/model_1523499889/model.ckpt.\n",
      "INFO:tensorflow:loss = 21.845428, step = 1\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/dictionary.pkl\", \"rb\") as f:\n",
    "    dictionary = pkl.load(f)\n",
    "# from tensorflow.python import debug as tf_debug\n",
    "# hook = tf_debug.TensorBoardDebugHook(\"localhost:6060\")\n",
    "classifier.train(input_fn=train_input_fn) #, hooks=[hook])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
