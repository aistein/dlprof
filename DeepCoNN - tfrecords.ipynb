{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/venv/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import tensorflow as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode):\n",
    "    emb_size = 50\n",
    "    filters=10\n",
    "    kernel_size=3\n",
    "    \n",
    "    with open(\"data/dictionary.pkl\", \"rb\") as f:\n",
    "        dictionary = pkl.load(f)\n",
    "    \n",
    "    values = list(range(len(dictionary)))\n",
    "    keys = list(dictionary)\n",
    "    \n",
    "    table = tf.contrib.lookup.HashTable(\n",
    "      tf.contrib.lookup.KeyValueTensorInitializer(keys, values), -1\n",
    "    )\n",
    "    \n",
    "    word_embeddings = tf.get_variable(\n",
    "        \"word_embeddings\",\n",
    "        shape=[len(dictionary), emb_size]\n",
    "    )\n",
    "    \n",
    "    u_inputs = features[0]\n",
    "    i_inputs = features[1]\n",
    "    \n",
    "    u_inputs = table.lookup(u_inputs)\n",
    "    i_inputs = table.lookup(i_inputs)\n",
    "\n",
    "    u_inputs = tf.nn.embedding_lookup(word_embeddings, u_inputs)\n",
    "    i_inputs = tf.nn.embedding_lookup(word_embeddings, i_inputs)\n",
    "    \n",
    "    user_conv1 = tf.layers.conv1d(\n",
    "        u_inputs,\n",
    "        filters,\n",
    "        kernel_size,\n",
    "        use_bias=True,\n",
    "        activation=tf.nn.tanh,\n",
    "        name=\"user_conv\")\n",
    "\n",
    "    item_conv1 = tf.layers.conv1d(\n",
    "        i_inputs,\n",
    "        filters,\n",
    "        kernel_size,\n",
    "        use_bias=True,\n",
    "        activation=tf.nn.tanh,\n",
    "        name=\"item_conv\")\n",
    "\n",
    "    user_max_pool1 = tf.layers.max_pooling1d(user_conv1, 2, 1)\n",
    "    item_max_pool1 = tf.layers.max_pooling1d(item_conv1, 2, 1)\n",
    "\n",
    "    user_flat = tf.layers.flatten(user_max_pool1)\n",
    "    item_flat = tf.layers.flatten(item_max_pool1)\n",
    "\n",
    "    user_dense = tf.layers.dense(user_flat, 64, activation=tf.nn.relu)\n",
    "    item_dense = tf.layers.dense(item_flat, 64, activation=tf.nn.relu)\n",
    "    \n",
    "    predictions = tf.reduce_sum( tf.multiply( user_dense, item_dense ), 1, keep_dims=True )\n",
    "    \n",
    "    output = {\n",
    "        \"rating\": predictions,\n",
    "        \"user_review_embedding\": user_flat,\n",
    "        \"item_review_embedding\": item_flat\n",
    "    }\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "\n",
    "    # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "    loss = tf.losses.mean_squared_error(labels, predictions)\n",
    "\n",
    "    # Configure the Training Op (for TRAIN mode)\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=0.0001)\n",
    "        train_op = optimizer.minimize(\n",
    "            loss=loss,\n",
    "            global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "    # Add evaluation metrics (for EVAL mode)\n",
    "    eval_metric_ops = {\n",
    "        \"mean square error\": tf.metrics.mean_squared_error(\n",
    "            labels=labels, predictions=predictions)\n",
    "    }\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "truncate_len = 800\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_truncate_fn(trunc_len):\n",
    "    def truncate_fn(user, item, rating):\n",
    "        return user[:trunc_len], item[:trunc_len], rating\n",
    "    return truncate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_fn(user, item, rating):\n",
    "    user = tf.string_split(user)\n",
    "    item = tf.string_split(item)\n",
    "    return user.values, item.values, rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_fn(record):\n",
    "    features = {\n",
    "            \"user_review\": tf.FixedLenSequenceFeature([], tf.string, allow_missing=True),\n",
    "            \"item_review\": tf.FixedLenSequenceFeature([], tf.string, allow_missing=True),\n",
    "            \"rating\": tf.FixedLenFeature([1], tf.float32)\n",
    "        }\n",
    "    parsed_features = tf.parse_single_example(record, features)\n",
    "    return parsed_features[\"user_review\"], parsed_features[\"item_review\"], parsed_features[\"rating\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_iterator(loc, batch_size, max_len, pad_value):\n",
    "    dataset = tf.data.TFRecordDataset(loc)\n",
    "    dataset = dataset.map(parse_fn, num_parallel_calls=batch_size)\n",
    "    dataset = dataset.map(split_fn, num_parallel_calls=batch_size)\n",
    "    dataset = dataset.map(get_truncate_fn(max_len), num_parallel_calls=batch_size)\n",
    "    dataset = dataset.padded_batch(batch_size, padded_shapes=([max_len], [max_len], [None]), padding_values=(pad_value, pad_value, 0.0))\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    return iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_input_fn():\n",
    "    train_dataset = get_dataset_iterator(\n",
    "        loc=\"data/train.tfrecords\",\n",
    "        batch_size=batch_size,\n",
    "        max_len=truncate_len,\n",
    "        pad_value=\"unk\")\n",
    "    nex = train_dataset.get_next()\n",
    "    return (nex[0], nex[1]), tf.cast(nex[2], tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_input_fn():\n",
    "    test_dataset = get_dataset_iterator(\n",
    "        loc=\"data/test.tfrecords\",\n",
    "        batch_size=batch_size,\n",
    "        max_len=truncate_len,\n",
    "        pad_value=\"unk\"\n",
    "    )\n",
    "    nex = test_dataset.get_next()\n",
    "    return (nex[0], nex[1]), nex[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'output/model_1523831640', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f79a941e2b0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "scoring_function = tf.estimator.Estimator(\n",
    "    model_fn=model_fn,\n",
    "    model_dir=\"output/model_\" + str(int(time.time())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /home/ubuntu/miniconda3/envs/venv/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n",
      "WARNING:tensorflow:From <ipython-input-2-1cbda9713abb>:55: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into output/model_1523831640/model.ckpt.\n",
      "INFO:tensorflow:loss = 15.340349, step = 1\n",
      "INFO:tensorflow:global_step/sec: 33.9628\n",
      "INFO:tensorflow:loss = 1.4795471, step = 101 (2.946 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.0581\n",
      "INFO:tensorflow:loss = 1.4250457, step = 201 (2.698 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.7622\n",
      "INFO:tensorflow:loss = 0.78281665, step = 301 (2.877 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.3997\n",
      "INFO:tensorflow:loss = 0.61032724, step = 401 (2.826 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.2073\n",
      "INFO:tensorflow:loss = 1.0034945, step = 501 (2.550 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.1556\n",
      "INFO:tensorflow:loss = 1.8547933, step = 601 (2.767 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.7945\n",
      "INFO:tensorflow:loss = 0.8207012, step = 701 (2.576 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.5029\n",
      "INFO:tensorflow:loss = 2.260113, step = 801 (2.817 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 824 into output/model_1523831640/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.8189739.\n",
      "ran 27.321994066238403 seconds\n"
     ]
    }
   ],
   "source": [
    "# from tensorflow.python import debug as tf_debug\n",
    "# hook = tf_debug.TensorBoardDebugHook(\"localhost:6060\")\n",
    "s = time.time()\n",
    "scoring_function.train(input_fn=train_input_fn) #, hooks=[hook])\n",
    "e = time.time()\n",
    "print(\"ran {} seconds\".format(e - s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-04-15-22:34:28\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from output/model_1523831640/model.ckpt-824\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-04-15-22:34:45\n",
      "INFO:tensorflow:Saving dict for global step 824: global_step = 824, loss = 1.0663562, mean square error = 1.0665209\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'global_step': 824, 'loss': 1.0663562, 'mean square error': 1.0665209}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoring_function.evaluate(input_fn=test_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_movie_lover = \"\"\"i really love action movies they are my favorite kind of movie because i love to watch the good guys\n",
    "win. some of my favorite actors are jet li and jackie chan because they were the last great actors who\n",
    "actually knew how to fight. modern action movie actors are just pretty faces and the editors swap camera\n",
    "angles when supposed hits make contact\"\"\"\n",
    "action_movie_hater = \"\"\"I really hate action movies. jackie chan and jet li are the worst. their old fashioned\n",
    "special effects, if you can even call them that, are out dated and boring. why are people even still paying\n",
    "for them to make movies\"\"\"\n",
    "item = \"\"\"this movie is great because of the way the strong, clever, hero saves the day at the end. as always\n",
    "jackie chans action directing and stunts are amazing, i'm so glad he doesn't use a stunt double liek\n",
    "some other actors that don't need to be mentioned\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predict_input_fn(user, item, trun_len):\n",
    "    def predict_input_fn():\n",
    "        original_user_review = [bytes(v, \"utf8\") for v in user.split()]\n",
    "        original_item_review = [bytes(v, \"utf8\") for v in item.split()]\n",
    "        r_user = tf.constant([original_user_review + [b\"unk\"] * (trun_len - len(original_user_review))])\n",
    "        r_item = tf.constant([original_item_review + [b\"unk\"] * (trun_len - len(original_item_review))])\n",
    "        return (r_user, r_item), None\n",
    "    return predict_input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Input graph does not use tf.data.Dataset or contain a QueueRunner. That means predict yields forever. This is probably a mistake.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from output/model_1523831640/model.ckpt-824\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "[3.1865366]\n"
     ]
    }
   ],
   "source": [
    "prediction = scoring_function.predict(input_fn=get_predict_input_fn(action_movie_lover, item, truncate_len))\n",
    "print(next(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Input graph does not use tf.data.Dataset or contain a QueueRunner. That means predict yields forever. This is probably a mistake.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from output/model_1523831640/model.ckpt-824\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "[2.827323]\n"
     ]
    }
   ],
   "source": [
    "prediction = scoring_function.predict(input_fn=get_predict_input_fn(action_movie_hater, item, truncate_len))\n",
    "print(next(prediction))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
